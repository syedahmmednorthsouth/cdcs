{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#sample data load\n",
    "df = pd.read_csv('./data/sample_data_100.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45471/2416226199.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['value_source_value'] = df['value_source_value'].str.replace(r'(\\d)(\\+)', lambda x: x.groups()[1]*int(x.groups()[0]))\n",
      "/tmp/ipykernel_45471/2416226199.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['value_source_value'] = df['value_source_value'].str.replace(r'(\\d+)(\\s+)(\\++)', lambda x: x.groups()[2])\n",
      "/tmp/ipykernel_45471/2416226199.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['value_source_value'] = df['value_source_value'].str.replace(r'(\\++)(\\d+)(\\s+)', lambda x: x.groups()[0])\n",
      "/tmp/ipykernel_45471/2416226199.py:18: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  _rh_pos_df = df[df['measurement_concept_id'] == 'BL7002']['value_source_value'].str.replace('+','rh+')\n"
     ]
    }
   ],
   "source": [
    "# 1) Data preparation\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def _general_preprocessing(df):\n",
    "    \n",
    "    # window user_encoding\n",
    "    df['value_source_value'] = df['value_source_value'].str.encode('utf8', errors = 'strict').str.decode('utf8', errors = 'strict')\n",
    "    \n",
    "    # lower, strip space, \\d\\+ restore\n",
    "    df['value_source_value'] = df['value_source_value'].str.lower()\n",
    "    df['value_source_value'] = df['value_source_value'].str.strip()\n",
    "    df['value_source_value'] = df['value_source_value'].str.replace(r'(\\d)(\\+)', lambda x: x.groups()[1]*int(x.groups()[0]))\n",
    "    df['value_source_value'] = df['value_source_value'].str.replace(r'(\\d+)(\\s+)(\\++)', lambda x: x.groups()[2])\n",
    "    df['value_source_value'] = df['value_source_value'].str.replace(r'(\\++)(\\d+)(\\s+)', lambda x: x.groups()[0])\n",
    "    \n",
    "    #replace + to Rh+ only for 'HJ1UHH1'(Rh type laboratory code) \n",
    "    _rh_pos_df = df[df['measurement_concept_id'] == 'BL7002']['value_source_value'].str.replace('+','rh+')\n",
    "    _rh_neg_df = df[df['measurement_concept_id'] == 'BL7002']['value_source_value'].str.replace('-','rh-')\n",
    "    df.loc[df.measurement_concept_id == 'HJ1UHH1', 'value_source_value'] = _rh_pos_df \n",
    "    df.loc[df.measurement_concept_id == 'HJ1UHH1', 'value_source_value'] = _rh_neg_df\n",
    "    return df\n",
    "\n",
    "df_with_freq = df.groupby(df.columns.tolist()).size().reset_index(name = 'Freq')\n",
    "df_with_freq_sort = df_with_freq.sort_values(by = 'Freq',ascending = False)\n",
    "df_cleaned = _general_preprocessing(df_with_freq_sort)\n",
    "df_cleaned_regrouped = df_cleaned.groupby(['measurement_concept_id','value_source_value'])\n",
    "df_cleaned_sort = df_cleaned_regrouped.sum().reset_index().sort_values(by = 'Freq', ascending = False)\n",
    "\n",
    "dist_dicts = defaultdict(dict)\n",
    "\n",
    "for cid, value, freq in df_cleaned_sort.values:\n",
    "    dist_dicts[cid][value] = freq\n",
    "    \n",
    "dist_dicts = dict(dist_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules_A: ['straw', 'clear', 'cloudy', 'yellow', 'amber', 'brown', 'orange']\n",
      "Rules_B: ['++', '+++', '++++']\n",
      "Rules_C: ['po.*', 'ne.*']\n",
      "Rules_D: ['ab', 'rh+']\n",
      "Rules_E: ['rea.*', 'non.*']\n"
     ]
    }
   ],
   "source": [
    "# 2) Laboratory tests Categorization\n",
    "import re\n",
    "import collections, re\n",
    "\n",
    "\n",
    "def get_majors_and_minors(dist_dict, acc_thr=99.5, diff_thr=100, n_thr=9):\n",
    "\n",
    "    if len(dist_dict) < 5:\n",
    "        return dist_dict\n",
    "\n",
    "    total = sum(dist_dict.values())\n",
    "    \n",
    "    tmp = {}\n",
    "    sorted_dist_dict = sorted(dist_dict.items(), key=lambda t: -t[1])\n",
    "    \n",
    "    for idx, (k, v) in enumerate(sorted_dist_dict):\n",
    "        \n",
    "        if idx==0:\n",
    "            prev = v\n",
    "            prev_acc = 0\n",
    "\n",
    "        acc_ratio = (prev_acc + v) / total * 100\n",
    "        \n",
    "        #Escape Rules\n",
    "        if (acc_ratio >= acc_thr): \n",
    "            tmp.update({k:v})\n",
    "            break\n",
    "            \n",
    "        if (idx>n_thr): \n",
    "            break\n",
    "            \n",
    "        tmp.update({k:v})\n",
    "        prev = v\n",
    "        prev_acc += v\n",
    "        \n",
    "    return tmp\n",
    "\n",
    "\n",
    "def get_groups(majors,\n",
    "    rules_A = ['straw','clear','cloudy','yellow','amber','brown','orange'],\n",
    "    rules_B = ['++', '+++', '++++'],\n",
    "    rules_C = ['po.*', 'ne.*'],\n",
    "    rules_D = ['ab','rh+'],\n",
    "    rules_E = ['rea.*', 'non.*']):\n",
    "\n",
    "    group_A = [] \n",
    "    group_B = [] \n",
    "    group_C = [] \n",
    "    group_D = []  \n",
    "    group_E = []  \n",
    "\n",
    "    message_form = '\\n'.join(['Rules_%s: {}' % c for c in 'ABCDE'])\n",
    "    print(message_form.format(rules_A, rules_B, rules_C,rules_D, rules_E))\n",
    "    \n",
    "    def is_group_A(major_dict):\n",
    "        return sum([1 for k in major_dict.keys() if k in rules_A])\n",
    "    def is_group_B(major_dict):\n",
    "        return sum([1 for k in major_dict.keys() if k in rules_B])\n",
    "    def is_group_C(major_dict):\n",
    "        return sum([1 for s in major_dict.keys() for r in rules_C if re.findall(r, s)])\n",
    "    def is_group_D(major_dict):\n",
    "        return sum([1 for k in major_dict.keys() if k in rules_D])\n",
    "    def is_group_E(major_dict):\n",
    "        return sum([1 for s in major_dict.keys() for r in rules_E if re.findall(r,s)])\n",
    "\n",
    "    for table_cid, major_dict in majors.items():\n",
    "        \n",
    "        if is_group_A(major_dict): \n",
    "            group_A.append(table_cid)\n",
    "            \n",
    "        elif is_group_B(major_dict):\n",
    "            group_B.append(table_cid)\n",
    "            \n",
    "        elif is_group_C(major_dict):\n",
    "            group_C.append(table_cid)\n",
    "            \n",
    "        elif is_group_D(major_dict): \n",
    "            group_D.append(table_cid)\n",
    "            \n",
    "        elif is_group_E(major_dict):\n",
    "            group_E.append(table_cid)\n",
    "            \n",
    "\n",
    "    merge_group_set = set(group_A + group_B + group_C + group_D + group_E)\n",
    "    group_others = [table_cid for table_cid in majors.keys() if table_cid not in merge_group_set]\n",
    "    return [group_A, group_B, group_C, group_D, group_E, group_others]\n",
    "\n",
    "\n",
    "def get_group_dict(group, regex=lambda x:x):\n",
    "    \n",
    "    group_dict = defaultdict(int)\n",
    "               \n",
    "    for table_cid in group:\n",
    "        for k, v in dist_dicts[table_cid].items():\n",
    "            group_dict[regex(re.sub(r'\\s+', ' ', k))] += v\n",
    "    \n",
    "    return group_dict\n",
    "\n",
    "\n",
    "majors = {table_cid:get_majors_and_minors(dist_dict, acc_thr=99.5) \n",
    "          for table_cid, dist_dict in dist_dicts.items()}\n",
    "groups = get_groups(majors)\n",
    "groups_dict = [get_group_dict(group) for group in groups] \n",
    "groups_sample = [group_dict.keys() for group_dict in groups_dict]\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "class Mapper():\n",
    "    def __init__(self, samples, ref_list):\n",
    "        self.samples = samples\n",
    "        self.ref_list = ref_list\n",
    "        \n",
    "    def create_feature_matrix(self, samples1, samples2):\n",
    "        def _create_feature_matrix(samples, refs):\n",
    "            #refsëŠ” feature list\n",
    "            result = []\n",
    "            row_idx = []\n",
    "            for r_idx, ng_str in enumerate(samples):\n",
    "                result.append([0]*len(refs))\n",
    "                for ng_char in ng_str:\n",
    "                    result[r_idx][refs.index(ng_char)] += 1\n",
    "            return result\n",
    "\n",
    "        samples1 = [s.lower() for s in samples1]\n",
    "        samples2 = [s.lower() for s in samples2]\n",
    "        refs = list(set(chain.from_iterable(samples1+samples2)))\n",
    "        matrix1 = _create_feature_matrix(samples1, refs)\n",
    "        matrix2 = _create_feature_matrix(samples2, refs)\n",
    "        return matrix1, matrix2\n",
    "    \n",
    "    def assign_to_ref(self, sample_vectors, ref_vectors, sample_list, ref_list):\n",
    "        def cosine_similarity_matrix(matrix1, matrix2):\n",
    "\n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(matrix1):\n",
    "                distance.append([])\n",
    "                for ref in matrix2:\n",
    "                    distance[s_idx].append(\n",
    "                        round(1-spatial.distance.cosine(sample, ref),2)\n",
    "                    )\n",
    "            return distance\n",
    "        \n",
    "        def lp_dist_matrix(matrix1, matrix2):\n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(matrix1):\n",
    "                distance.append([])\n",
    "                for ref in matrix2:\n",
    "                    distance[s_idx].append(\n",
    "                        round(spatial.distance.euclidean(sample, ref),2)\n",
    "                    )\n",
    "            return distance\n",
    "        \n",
    "        def levenshtein_measure(sample_list, ref_list):\n",
    "            def levenshtein(s1, s2):\n",
    "            # based on Wikipedia/Levenshtein_distance\n",
    "                if len(s1) < len(s2):\n",
    "                    return levenshtein(s2, s1)\n",
    "\n",
    "                if len(s2) == 0:\n",
    "                    return len(s1)\n",
    "    \n",
    "                previous_row = range(len(s2) + 1)\n",
    "                for i, c1 in enumerate(s1):\n",
    "                    current_row = [i + 1]\n",
    "                    for j, c2 in enumerate(s2):\n",
    "                        insertions = previous_row[j + 1] + 1\n",
    "                        deletions = current_row[j] + 1\n",
    "                        substitutions = previous_row[j] + (c1 != c2)\n",
    "                        current_row.append(min(insertions, deletions, substitutions))\n",
    "                    previous_row = current_row\n",
    "    \n",
    "                return previous_row[-1]\n",
    "    \n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(sample_list):\n",
    "                distance.append([])\n",
    "                for ref in ref_list:\n",
    "                    distance[s_idx].append(  )\n",
    "            return distance\n",
    "\n",
    "        sample_list = list(sample_list)\n",
    "\n",
    "        cos_scores = cosine_similarity_matrix(sample_vectors, ref_vectors)\n",
    "        lev_scores  = levenshtein_measure(sample_list, ref_list)\n",
    "        lp_dist_scores = lp_dist_matrix(sample_vectors, ref_vectors)\n",
    "        \n",
    "        \n",
    "        result = []\n",
    "        outlier = []\n",
    "        for s_idx, sample in enumerate(sample_vectors):\n",
    "            max_cos_score = max(cos_scores[s_idx])\n",
    "            max_cos_idx = cos_scores[s_idx].index(max_cos_score)\n",
    "            max_cos_cnt = cos_scores[s_idx].count(max_cos_score)\n",
    "            min_lp_dist_score = min(lp_dist_scores[s_idx])\n",
    "            min_lp_dist_idx = lp_dist_scores[s_idx].index(min_lp_dist_score)\n",
    "            min_lp_dist_cnt = lp_dist_scores[s_idx].count(min_lp_dist_score)\n",
    "            min_lev_score = min(lev_scores[s_idx])\n",
    "            min_lev_idx = lev_scores[s_idx].index(min_lev_score)\n",
    "            \n",
    "            if max_cos_cnt == len(cos_scores[s_idx]):\n",
    "                outlier.append(\n",
    "                    [sample_list[s_idx],\n",
    "                     ref_list[max_cos_idx],\n",
    "                     cos_scores[s_idx]]\n",
    "                )\n",
    "            else:\n",
    "                result.append(\n",
    "                    [sample_list[s_idx],\n",
    "                     ref_list[max_cos_idx],\n",
    "                     cos_scores[s_idx],\n",
    "                     ref_list[min_lp_dist_idx],\n",
    "                     lp_dist_scores[s_idx],\n",
    "                     ref_list[min_lev_idx],\n",
    "                     lev_scores[s_idx],\n",
    "                     'cosine' if max_cos_cnt <= 1 else 'Eucl',\n",
    "                     ref_list[max_cos_idx] if max_cos_cnt <= 1 else ref_list[min_lp_dist_idx]]\n",
    "                )\n",
    "        result_df = pd.DataFrame(result, columns=['smp','ref','cos','ref_lp','lp','ref_lev','lv','ecul','refe'])\n",
    "        result_df.to_csv(\"result_df.csv\")\n",
    "        return result, outlier\n",
    "    \n",
    "    def get_report_df(self, results):\n",
    "\n",
    "        report_df = pd.DataFrame(\n",
    "            results,\n",
    "            columns=[\n",
    "                'Data',\n",
    "                'cos_word',\n",
    "                'cos_score',\n",
    "                'euc_word',\n",
    "                'euc_score',\n",
    "                'lev_word',\n",
    "                'lev_score',\n",
    "                'Measure',\n",
    "                'Final'\n",
    "            ]\n",
    "        )\n",
    "        report_df.to_csv(\"r.csv\")\n",
    "        report_df = report_df[['Data','Final']]\n",
    "        \n",
    "        return report_df\n",
    "    \n",
    "    def analyze(self):\n",
    "        self._sample_vectors, self._ref_vectors = self.create_feature_matrix(\n",
    "            self.samples, self.ref_list)\n",
    "        \n",
    "        self._cluster_results, self._outlier = self.assign_to_ref(\n",
    "            self._sample_vectors, self._ref_vectors, self.samples, self.ref_list)\n",
    "        \n",
    "        self.report_df= self.get_report_df(self._cluster_results)\n",
    "\n",
    "        \n",
    "ref_list_A = ['straw', 'amber', 'brown', 'green', 'yellow', 'orange', 'black','blue', 'red', 'other', 'clear', 'cloudy', 'hazy', 'turbid', 'bloody']\n",
    "ref_list_B = ['neg', 'trace', '+', '++', '+++', '++++']\n",
    "ref_list_C = ['posi', 'neg-','weak-pos']\n",
    "ref_list_D = ['a','b','c','ab','cisab','rh+','rh-','partiald','weakd','variantd'] \n",
    "ref_list_E = ['reac', 'non-reac','weak-reac']\n",
    "\n",
    "groups_agents = [\n",
    "    Mapper(sample, ref_list) for sample, ref_list in zip(\n",
    "        groups_sample[:-1],\n",
    "        [ref_list_A, ref_list_B, ref_list_C,ref_list_D,ref_list_E]\n",
    "    )\n",
    "]\n",
    "\n",
    "for agent in groups_agents:\n",
    "    agent.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "class Mapper():\n",
    "    def __init__(self, samples, ref_list):\n",
    "        self.samples = samples\n",
    "        self.ref_list = ref_list\n",
    "        \n",
    "    def create_feature_matrix(self, samples1, samples2):\n",
    "        def _create_feature_matrix(samples, refs):\n",
    "            #refsëŠ” feature list\n",
    "            result = []\n",
    "            row_idx = []\n",
    "            for r_idx, ng_str in enumerate(samples):\n",
    "                result.append([0]*len(refs))\n",
    "                for ng_char in ng_str:\n",
    "                    result[r_idx][refs.index(ng_char)] += 1\n",
    "            return result\n",
    "\n",
    "        samples1 = [s.lower() for s in samples1]\n",
    "        samples2 = [s.lower() for s in samples2]\n",
    "        refs = list(set(chain.from_iterable(samples1+samples2)))\n",
    "        matrix1 = _create_feature_matrix(samples1, refs)\n",
    "        matrix2 = _create_feature_matrix(samples2, refs)\n",
    "        return matrix1, matrix2\n",
    "    \n",
    "    def assign_to_ref(self, sample_vectors, ref_vectors, sample_list, ref_list):\n",
    "#         def cosine_similarity_matrix(matrix1, matrix2):\n",
    "\n",
    "#             distance = []\n",
    "#             for s_idx, sample in enumerate(matrix1):\n",
    "#                 distance.append([])\n",
    "#                 for ref in matrix2:\n",
    "#                     distance[s_idx].append(\n",
    "#                         round(1-spatial.distance.cosine(sample, ref),2)\n",
    "#                     )\n",
    "#             return distance\n",
    "        \n",
    "        def lp_dist_matrix(matrix1, matrix2):\n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(matrix1):\n",
    "                distance.append([])\n",
    "                for ref in matrix2:\n",
    "                    distance[s_idx].append(\n",
    "                        round(spatial.distance.euclidean(sample, ref),2)\n",
    "                    )\n",
    "            return distance\n",
    "        \n",
    "        def levenshtein_measure(sample_list, ref_list):\n",
    "            def levenshtein(s1, s2):\n",
    "            # based on Wikipedia/Levenshtein_distance\n",
    "                if len(s1) < len(s2):\n",
    "                    return levenshtein(s2, s1)\n",
    "\n",
    "                if len(s2) == 0:\n",
    "                    return len(s1)\n",
    "    \n",
    "                previous_row = range(len(s2) + 1)\n",
    "                for i, c1 in enumerate(s1):\n",
    "                    current_row = [i + 1]\n",
    "                    for j, c2 in enumerate(s2):\n",
    "                        insertions = previous_row[j + 1] + 1\n",
    "                        deletions = current_row[j] + 1\n",
    "                        substitutions = previous_row[j] + (c1 != c2)\n",
    "                        current_row.append(min(insertions, deletions, substitutions))\n",
    "                    previous_row = current_row\n",
    "    \n",
    "                return previous_row[-1]\n",
    "    \n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(sample_list):\n",
    "                distance.append([])\n",
    "                for ref in ref_list:\n",
    "                    distance[s_idx].append(levenshtein(sample, ref))\n",
    "            return distance\n",
    "        # Python3 implementation of above approach\n",
    "        from math import floor\n",
    "        def jaro_winkler_measures(sample_list, ref_list):\n",
    "            # Function to calculate the\n",
    "            # Jaro Similarity of two strings\n",
    "            def jaro_distance(s1, s2) :\n",
    "\n",
    "                # If the strings are equal\n",
    "                if (s1 == s2) :\n",
    "                    return 1.0;\n",
    "\n",
    "                # Length of two strings\n",
    "                len1 = len(s1);\n",
    "                len2 = len(s2);\n",
    "\n",
    "                if (len1 == 0 or len2 == 0) :\n",
    "                    return 0.0;\n",
    "\n",
    "                # Maximum distance upto which matching\n",
    "                # is allowed\n",
    "                max_dist = (max(len(s1), len(s2)) // 2 ) - 1;\n",
    "\n",
    "                # Count of matches\n",
    "                match = 0;\n",
    "\n",
    "                # Hash for matches\n",
    "                hash_s1 = [0] * len(s1) ;\n",
    "                hash_s2 = [0] * len(s2) ;\n",
    "\n",
    "                # Traverse through the first string\n",
    "                for i in range(len1) :\n",
    "\n",
    "                    # Check if there is any matches\n",
    "                    for j in range( max(0, i - max_dist),\n",
    "                                min(len2, i + max_dist + 1)) :\n",
    "\n",
    "                        # If there is a match\n",
    "                        if (s1[i] == s2[j] and hash_s2[j] == 0) :\n",
    "                            hash_s1[i] = 1;\n",
    "                            hash_s2[j] = 1;\n",
    "                            match += 1;\n",
    "                            break;\n",
    "\n",
    "                # If there is no match\n",
    "                if (match == 0) :\n",
    "                    return 0.0;\n",
    "\n",
    "                # Number of transpositions\n",
    "                t = 0;\n",
    "\n",
    "                point = 0;\n",
    "\n",
    "                # Count number of occurrences\n",
    "                # where two characters match but\n",
    "                # there is a third matched character\n",
    "                # in between the indices\n",
    "                for i in range(len1) :\n",
    "                    if (hash_s1[i]) :\n",
    "\n",
    "                        # Find the next matched character\n",
    "                        # in second string\n",
    "                        while (hash_s2[point] == 0) :\n",
    "                            point += 1;\n",
    "\n",
    "                        if (s1[i] != s2[point]) :\n",
    "                            point += 1;\n",
    "                            t += 1;\n",
    "                        else :\n",
    "                            point += 1;\n",
    "\n",
    "                    t /= 2;\n",
    "\n",
    "                # Return the Jaro Similarity\n",
    "                return ((match / len1 + match / len2 +\n",
    "                        (match - t) / match ) / 3.0);\n",
    "\n",
    "            # Jaro Winkler Similarity\n",
    "            def jaro_Winkler(s1, s2) :\n",
    "\n",
    "                jaro_dist = jaro_distance(s1, s2);\n",
    "\n",
    "                # If the jaro Similarity is above a threshold\n",
    "                if (jaro_dist > 0.7) :\n",
    "\n",
    "                    # Find the length of common prefix\n",
    "                    prefix = 0;\n",
    "\n",
    "                    for i in range(min(len(s1), len(s2))) :\n",
    "\n",
    "                        # If the characters match\n",
    "                        if (s1[i] == s2[i]) :\n",
    "                            prefix += 1;\n",
    "\n",
    "                        # Else break\n",
    "                        else :\n",
    "                            break;\n",
    "\n",
    "                    # Maximum of 4 characters are allowed in prefix\n",
    "                    prefix = min(4, prefix);\n",
    "\n",
    "                    # Calculate jaro winkler Similarity\n",
    "                    jaro_dist += 0.1 * prefix * (1 - jaro_dist);\n",
    "\n",
    "                return jaro_dist;\n",
    "            \n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(sample_list):\n",
    "                distance.append([])\n",
    "                for ref in ref_list:\n",
    "                    distance[s_idx].append(jaro_Winkler(sample, ref))\n",
    "            return distance\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        sample_list = list(sample_list)\n",
    "\n",
    "        # cos_scores = cosine_similarity_matrix(sample_vectors, ref_vectors)\n",
    "        lev_scores  = levenshtein_measure(sample_list, ref_list)\n",
    "        lp_dist_scores = lp_dist_matrix(sample_vectors, ref_vectors)\n",
    "        jw_scores  = jaro_winkler_measures(sample_list, ref_list)\n",
    "        \n",
    "        result = []\n",
    "        outlier = []\n",
    "        for s_idx, sample in enumerate(sample_vectors):\n",
    "            # max_cos_score = max(cos_scores[s_idx])\n",
    "            # max_cos_idx = cos_scores[s_idx].index(max_cos_score)\n",
    "            # max_cos_cnt = cos_scores[s_idx].count(max_cos_score)\n",
    "            max_jw_score = max(jw_scores[s_idx])\n",
    "            max_jw_idx = jw_scores[s_idx].index(max_jw_score)\n",
    "            max_jw_cnt = jw_scores[s_idx].count(max_jw_score )\n",
    "            min_lp_dist_score = min(lp_dist_scores[s_idx])\n",
    "            min_lp_dist_idx = lp_dist_scores[s_idx].index(min_lp_dist_score)\n",
    "            min_lp_dist_cnt = lp_dist_scores[s_idx].count(min_lp_dist_score)\n",
    "            min_lev_score = min(lev_scores[s_idx])\n",
    "            min_lev_idx = lev_scores[s_idx].index(min_lev_score)\n",
    "            \n",
    "            if max_cos_cnt == len(cos_scores[s_idx]):\n",
    "                outlier.append(\n",
    "                    [sample_list[s_idx],\n",
    "                     ref_list[max_cos_idx],\n",
    "                     cos_scores[s_idx]]\n",
    "                )\n",
    "            else:\n",
    "                result.append(\n",
    "                    [sample_list[s_idx],\n",
    "                     ref_list[max_cos_idx],\n",
    "                     cos_scores[s_idx],\n",
    "                     ref_list[min_lp_dist_idx],\n",
    "                     lp_dist_scores[s_idx],\n",
    "                     ref_list[min_lev_idx],\n",
    "                     lev_scores[s_idx],\n",
    "                     'cosine' if max_cos_cnt <= 1 else 'Eucl',\n",
    "                     ref_list[max_cos_idx] if max_cos_cnt <= 1 else ref_list[min_lp_dist_idx]]\n",
    "                )\n",
    "\n",
    "        return result, outlier\n",
    "    \n",
    "    def get_report_df(self, results):\n",
    "\n",
    "        report_df = pd.DataFrame(\n",
    "            results,\n",
    "            columns=[\n",
    "                'Data',\n",
    "                'cos_word',\n",
    "                'cos_score',\n",
    "                'euc_word',\n",
    "                'euc_score',\n",
    "                'lev_word',\n",
    "                'lev_score',\n",
    "                'Measure',\n",
    "                'Final'\n",
    "            ]\n",
    "        )\n",
    "        report_df.to_csv(\"r.csv\")\n",
    "        report_df = report_df[['Data','Final']]\n",
    "        \n",
    "        return report_df\n",
    "    \n",
    "    def analyze(self):\n",
    "        self._sample_vectors, self._ref_vectors = self.create_feature_matrix(\n",
    "            self.samples, self.ref_list)\n",
    "        \n",
    "        self._cluster_results, self._outlier = self.assign_to_ref(\n",
    "            self._sample_vectors, self._ref_vectors, self.samples, self.ref_list)\n",
    "        \n",
    "        self.report_df= self.get_report_df(self._cluster_results)\n",
    "\n",
    "        \n",
    "ref_list_A = ['straw', 'amber', 'brown', 'green', 'yellow', 'orange', 'black','blue', 'red', 'other', 'clear', 'cloudy', 'hazy', 'turbid', 'bloody']\n",
    "ref_list_B = ['neg', 'trace', '+', '++', '+++', '++++']\n",
    "ref_list_C = ['posi', 'neg-','weak-pos']\n",
    "ref_list_D = ['a','b','c','ab','cisab','rh+','rh-','partiald','weakd','variantd'] \n",
    "ref_list_E = ['reac', 'non-reac','weak-reac']\n",
    "\n",
    "groups_agents = [\n",
    "    Mapper(sample, ref_list) for sample, ref_list in zip(\n",
    "        groups_sample[:-1],\n",
    "        [ref_list_A, ref_list_B, ref_list_C,ref_list_D,ref_list_E]\n",
    "    )\n",
    "]\n",
    "\n",
    "for agent in groups_agents:\n",
    "    agent.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "class Mapper():\n",
    "    def __init__(self, samples, ref_list):\n",
    "        self.samples = samples\n",
    "        self.ref_list = ref_list\n",
    "        \n",
    "    def create_feature_matrix(self, samples1, samples2):\n",
    "        def _create_feature_matrix(samples, refs):\n",
    "            #refsëŠ” feature list\n",
    "            result = []\n",
    "            row_idx = []\n",
    "            for r_idx, ng_str in enumerate(samples):\n",
    "                result.append([0]*len(refs))\n",
    "                for ng_char in ng_str:\n",
    "                    result[r_idx][refs.index(ng_char)] += 1\n",
    "            return result\n",
    "\n",
    "        samples1 = [s.lower() for s in samples1]\n",
    "        samples2 = [s.lower() for s in samples2]\n",
    "        refs = list(set(chain.from_iterable(samples1+samples2)))\n",
    "        matrix1 = _create_feature_matrix(samples1, refs)\n",
    "        matrix2 = _create_feature_matrix(samples2, refs)\n",
    "        return matrix1, matrix2\n",
    "    \n",
    "    def assign_to_ref(self, sample_vectors, ref_vectors, sample_list, ref_list):\n",
    "        def cosine_similarity_matrix(matrix1, matrix2):\n",
    "\n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(matrix1):\n",
    "                distance.append([])\n",
    "                for ref in matrix2:\n",
    "                    distance[s_idx].append(\n",
    "                        round(1-spatial.distance.cosine(sample, ref),2)\n",
    "                    )\n",
    "            return distance\n",
    "        from math import floor\n",
    "        def jaro_winkler_measures(sample_list, ref_list):\n",
    "            # Function to calculate the\n",
    "            # Jaro Similarity of two strings\n",
    "            def jaro_distance(s1, s2) :\n",
    "\n",
    "                # If the strings are equal\n",
    "                if (s1 == s2) :\n",
    "                    return 1.0;\n",
    "\n",
    "                # Length of two strings\n",
    "                len1 = len(s1);\n",
    "                len2 = len(s2);\n",
    "\n",
    "                if (len1 == 0 or len2 == 0) :\n",
    "                    return 0.0;\n",
    "\n",
    "                # Maximum distance upto which matching\n",
    "                # is allowed\n",
    "                max_dist = (max(len(s1), len(s2)) // 2 ) - 1;\n",
    "\n",
    "                # Count of matches\n",
    "                match = 0;\n",
    "\n",
    "                # Hash for matches\n",
    "                hash_s1 = [0] * len(s1) ;\n",
    "                hash_s2 = [0] * len(s2) ;\n",
    "\n",
    "                # Traverse through the first string\n",
    "                for i in range(len1) :\n",
    "\n",
    "                    # Check if there is any matches\n",
    "                    for j in range( max(0, i - max_dist),\n",
    "                                min(len2, i + max_dist + 1)) :\n",
    "\n",
    "                        # If there is a match\n",
    "                        if (s1[i] == s2[j] and hash_s2[j] == 0) :\n",
    "                            hash_s1[i] = 1;\n",
    "                            hash_s2[j] = 1;\n",
    "                            match += 1;\n",
    "                            break;\n",
    "\n",
    "                # If there is no match\n",
    "                if (match == 0) :\n",
    "                    return 0.0;\n",
    "\n",
    "                # Number of transpositions\n",
    "                t = 0;\n",
    "\n",
    "                point = 0;\n",
    "\n",
    "                # Count number of occurrences\n",
    "                # where two characters match but\n",
    "                # there is a third matched character\n",
    "                # in between the indices\n",
    "                for i in range(len1) :\n",
    "                    if (hash_s1[i]) :\n",
    "\n",
    "                        # Find the next matched character\n",
    "                        # in second string\n",
    "                        while (hash_s2[point] == 0) :\n",
    "                            point += 1;\n",
    "\n",
    "                        if (s1[i] != s2[point]) :\n",
    "                            point += 1;\n",
    "                            t += 1;\n",
    "                        else :\n",
    "                            point += 1;\n",
    "\n",
    "                    t /= 2;\n",
    "\n",
    "                # Return the Jaro Similarity\n",
    "                return ((match / len1 + match / len2 +\n",
    "                        (match - t) / match ) / 3.0);\n",
    "\n",
    "            # Jaro Winkler Similarity\n",
    "            def jaro_Winkler(s1, s2) :\n",
    "\n",
    "                jaro_dist = jaro_distance(s1, s2);\n",
    "\n",
    "                # If the jaro Similarity is above a threshold\n",
    "                if (jaro_dist > 0.7) :\n",
    "\n",
    "                    # Find the length of common prefix\n",
    "                    prefix = 0;\n",
    "\n",
    "                    for i in range(min(len(s1), len(s2))) :\n",
    "\n",
    "                        # If the characters match\n",
    "                        if (s1[i] == s2[i]) :\n",
    "                            prefix += 1;\n",
    "\n",
    "                        # Else break\n",
    "                        else :\n",
    "                            break;\n",
    "\n",
    "                    # Maximum of 4 characters are allowed in prefix\n",
    "                    prefix = min(4, prefix);\n",
    "\n",
    "                    # Calculate jaro winkler Similarity\n",
    "                    jaro_dist += 0.1 * prefix * (1 - jaro_dist);\n",
    "\n",
    "                return jaro_dist;\n",
    "            \n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(sample_list):\n",
    "                distance.append([])\n",
    "                for ref in ref_list:\n",
    "                    distance[s_idx].append(jaro_Winkler(sample, ref))\n",
    "            return distance\n",
    "        \n",
    "        def lp_dist_matrix(matrix1, matrix2):\n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(matrix1):\n",
    "                distance.append([])\n",
    "                for ref in matrix2:\n",
    "                    distance[s_idx].append(\n",
    "                        round(spatial.distance.euclidean(sample, ref),2)\n",
    "                    )\n",
    "            return distance\n",
    "        \n",
    "        def levenshtein_measure(sample_list, ref_list):\n",
    "            def levenshtein(s1, s2):\n",
    "            # based on Wikipedia/Levenshtein_distance\n",
    "                if len(s1) < len(s2):\n",
    "                    return levenshtein(s2, s1)\n",
    "\n",
    "                if len(s2) == 0:\n",
    "                    return len(s1)\n",
    "    \n",
    "                previous_row = range(len(s2) + 1)\n",
    "                for i, c1 in enumerate(s1):\n",
    "                    current_row = [i + 1]\n",
    "                    for j, c2 in enumerate(s2):\n",
    "                        insertions = previous_row[j + 1] + 1\n",
    "                        deletions = current_row[j] + 1\n",
    "                        substitutions = previous_row[j] + (c1 != c2)\n",
    "                        current_row.append(min(insertions, deletions, substitutions))\n",
    "                    previous_row = current_row\n",
    "    \n",
    "                return previous_row[-1]\n",
    "    \n",
    "            distance = []\n",
    "            for s_idx, sample in enumerate(sample_list):\n",
    "                distance.append([])\n",
    "                for ref in ref_list:\n",
    "                    distance[s_idx].append(levenshtein(sample, ref))\n",
    "            return distance\n",
    "\n",
    "        \n",
    "        sample_list = list(sample_list)\n",
    "\n",
    "        cos_scores = cosine_similarity_matrix(sample_vectors, ref_vectors)\n",
    "        jw_scores = jaro_winkler_measures(sample_vectors, ref_vectors)\n",
    "        lev_scores  = levenshtein_measure(sample_list, ref_list)\n",
    "        lp_dist_scores = lp_dist_matrix(sample_vectors, ref_vectors)\n",
    "        \n",
    "        result = []\n",
    "        outlier = []\n",
    "        for s_idx, sample in enumerate(sample_vectors):\n",
    "            max_cos_score = max(cos_scores[s_idx])\n",
    "            max_cos_idx = cos_scores[s_idx].index(max_cos_score)\n",
    "            max_cos_cnt = cos_scores[s_idx].count(max_cos_score)\n",
    "            max_jw_score = max(jw_scores[s_idx])\n",
    "            max_jw_idx = jw_scores[s_idx].index(max_jw_score)\n",
    "            max_jw_cnt = jw_scores[s_idx].count(max_jw_score)\n",
    "            min_lp_dist_score = min(lp_dist_scores[s_idx])\n",
    "            min_lp_dist_idx = lp_dist_scores[s_idx].index(min_lp_dist_score)\n",
    "            min_lp_dist_cnt = lp_dist_scores[s_idx].count(min_lp_dist_score)\n",
    "            min_lev_score = min(lev_scores[s_idx])\n",
    "            min_lev_idx = lev_scores[s_idx].index(min_lev_score)\n",
    "            \n",
    "            if max_jw_cnt == len(jw_scores[s_idx]):\n",
    "                outlier.append(\n",
    "                    [sample_list[s_idx],\n",
    "                     ref_list[max_cos_idx],\n",
    "                     jw_scores[s_idx]]\n",
    "                )\n",
    "            else:\n",
    "                result.append(\n",
    "                    [sample_list[s_idx],\n",
    "                     ref_list[max_cos_idx],\n",
    "                     jw_scores[s_idx],\n",
    "                     ref_list[min_lp_dist_idx],\n",
    "                     lp_dist_scores[s_idx],\n",
    "                     ref_list[min_lev_idx],\n",
    "                     lev_scores[s_idx],\n",
    "                     'jw' if max_jw_cnt <= 1 else 'Eucl',\n",
    "                     ref_list[max_jw_idx] if max_jw_cnt <= 1 else ref_list[min_lp_dist_idx]]\n",
    "                )\n",
    "\n",
    "        return result, outlier\n",
    "    \n",
    "    def get_report_df(self, results):\n",
    "\n",
    "        report_df = pd.DataFrame(\n",
    "            results,\n",
    "            columns=[\n",
    "                'Data',\n",
    "                'jw_word',\n",
    "                'jw_score',\n",
    "                'euc_word',\n",
    "                'euc_score',\n",
    "                'lev_word',\n",
    "                'lev_score',\n",
    "                'Measure',\n",
    "                'Final'\n",
    "            ]\n",
    "        )\n",
    "        report_df = report_df[['Data','jw_word','jw_score','euc_word','euc_score','lev_word','lev_score','Measure','Final']]\n",
    "        return report_df\n",
    "    \n",
    "    def analyze(self):\n",
    "        self._sample_vectors, self._ref_vectors = self.create_feature_matrix(\n",
    "            self.samples, self.ref_list)\n",
    "        \n",
    "        self._cluster_results, self._outlier = self.assign_to_ref(\n",
    "            self._sample_vectors, self._ref_vectors, self.samples, self.ref_list)\n",
    "        \n",
    "        self.report_df= self.get_report_df(self._cluster_results)\n",
    "\n",
    "        \n",
    "ref_list_A = ['straw', 'amber', 'brown', 'green', 'yellow', 'orange', 'black','blue', 'red', 'other', 'clear', 'cloudy', 'hazy', 'turbid', 'bloody']\n",
    "ref_list_B = ['neg', 'trace', '+', '++', '+++', '++++']\n",
    "ref_list_C = ['posi', 'neg-','weak-pos']\n",
    "ref_list_D = ['a','b','c','ab','cisab','rh+','rh-','partiald','weakd','variantd'] \n",
    "ref_list_E = ['reac', 'non-reac','weak-reac']\n",
    "\n",
    "groups_agents = [\n",
    "    Mapper(sample, ref_list) for sample, ref_list in zip(\n",
    "        groups_sample[:-1],\n",
    "        [ref_list_A, ref_list_B, ref_list_C,ref_list_D,ref_list_E]\n",
    "    )\n",
    "]\n",
    "\n",
    "for agent in groups_agents:\n",
    "    agent.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>jw_word</th>\n",
       "      <th>jw_score</th>\n",
       "      <th>euc_word</th>\n",
       "      <th>euc_score</th>\n",
       "      <th>lev_word</th>\n",
       "      <th>lev_score</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clear</td>\n",
       "      <td>clear</td>\n",
       "      <td>[0.9957737255096435, 0.9983007303873699, 0.993...</td>\n",
       "      <td>clear</td>\n",
       "      <td>[2.45, 2.0, 2.83, 2.45, 2.65, 2.24, 2.0, 2.24,...</td>\n",
       "      <td>clear</td>\n",
       "      <td>[4, 4, 5, 4, 5, 6, 4, 4, 4, 4, 0, 4, 5, 6, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>[0.965404487074467, 0.9533089855261015, 0.9696...</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>[3.32, 3.32, 3.0, 3.61, 2.45, 3.16, 2.65, 2.45...</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>[6, 6, 5, 6, 6, 6, 5, 4, 5, 6, 4, 0, 5, 6, 2]</td>\n",
       "      <td>jw</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hazy</td>\n",
       "      <td>hazy</td>\n",
       "      <td>[0.969675800925807, 0.9784476189864308, 0.9663...</td>\n",
       "      <td>hazy</td>\n",
       "      <td>[2.65, 2.65, 3.0, 3.32, 3.16, 2.83, 2.65, 2.83...</td>\n",
       "      <td>hazy</td>\n",
       "      <td>[5, 5, 5, 5, 6, 5, 4, 4, 4, 5, 5, 5, 0, 6, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>hazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>straw</td>\n",
       "      <td>straw</td>\n",
       "      <td>[1.0, 0.9938768100738525, 0.997392733891805, 0...</td>\n",
       "      <td>straw</td>\n",
       "      <td>[0.0, 2.45, 2.45, 3.16, 3.32, 2.65, 2.83, 3.0,...</td>\n",
       "      <td>straw</td>\n",
       "      <td>[0, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 6, 5, 5, 6]</td>\n",
       "      <td>jw</td>\n",
       "      <td>straw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "      <td>[0.9619675786871659, 0.9662853140580027, 0.969...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>[3.32, 3.32, 3.0, 3.32, 0.0, 3.16, 3.0, 2.45, ...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>[5, 6, 5, 6, 0, 6, 5, 5, 5, 6, 5, 6, 6, 6, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amber</td>\n",
       "      <td>amber</td>\n",
       "      <td>[0.9938768100738525, 1.0, 0.9957975864410401, ...</td>\n",
       "      <td>amber</td>\n",
       "      <td>[2.45, 0.0, 2.45, 2.45, 3.32, 2.24, 2.45, 2.24...</td>\n",
       "      <td>amber</td>\n",
       "      <td>[5, 0, 5, 4, 6, 5, 5, 4, 4, 3, 4, 6, 5, 5, 6]</td>\n",
       "      <td>jw</td>\n",
       "      <td>amber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brown</td>\n",
       "      <td>brown</td>\n",
       "      <td>[0.997392733891805, 0.9957975864410401, 1.0, 0...</td>\n",
       "      <td>brown</td>\n",
       "      <td>[2.45, 2.45, 0.0, 2.83, 3.0, 2.24, 2.83, 2.65,...</td>\n",
       "      <td>brown</td>\n",
       "      <td>[4, 5, 0, 3, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 4]</td>\n",
       "      <td>jw</td>\n",
       "      <td>brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reddish</td>\n",
       "      <td>red</td>\n",
       "      <td>[0.9735094492059004, 0.9610682778609426, 0.965...</td>\n",
       "      <td>red</td>\n",
       "      <td>[3.16, 3.16, 3.46, 3.16, 3.87, 3.32, 3.74, 3.3...</td>\n",
       "      <td>red</td>\n",
       "      <td>[7, 7, 7, 6, 6, 7, 7, 7, 4, 7, 7, 7, 7, 6, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>straw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>orange</td>\n",
       "      <td>orange</td>\n",
       "      <td>[0.9661128830491451, 0.9556621183428847, 0.975...</td>\n",
       "      <td>orange</td>\n",
       "      <td>[2.65, 2.24, 2.24, 1.73, 3.16, 0.0, 3.0, 2.83,...</td>\n",
       "      <td>orange</td>\n",
       "      <td>[5, 5, 5, 5, 6, 0, 5, 5, 5, 5, 6, 6, 5, 6, 6]</td>\n",
       "      <td>jw</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "      <td>[0.9358082516988118, 0.9571988254123264, 0.928...</td>\n",
       "      <td>red</td>\n",
       "      <td>[2.45, 2.0, 2.45, 2.0, 3.0, 2.24, 2.83, 2.24, ...</td>\n",
       "      <td>red</td>\n",
       "      <td>[4, 4, 4, 3, 5, 5, 5, 4, 0, 4, 4, 5, 4, 4, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>[0.995766019821167, 0.997296126683553, 0.99521...</td>\n",
       "      <td>other</td>\n",
       "      <td>[2.45, 2.45, 2.45, 2.45, 3.0, 2.24, 3.16, 2.65...</td>\n",
       "      <td>other</td>\n",
       "      <td>[4, 3, 5, 4, 6, 5, 5, 4, 4, 0, 4, 6, 5, 6, 6]</td>\n",
       "      <td>jw</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "      <td>[0.9399764442443849, 0.9599735514322917, 0.933...</td>\n",
       "      <td>green</td>\n",
       "      <td>[3.16, 2.45, 2.83, 0.0, 3.32, 1.73, 3.46, 2.65...</td>\n",
       "      <td>green</td>\n",
       "      <td>[5, 4, 3, 0, 6, 5, 5, 4, 3, 4, 4, 6, 5, 5, 6]</td>\n",
       "      <td>jw</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>colorless</td>\n",
       "      <td>yellow</td>\n",
       "      <td>[0.8949912276922488, 0.89462890625, 0.89499137...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>[3.74, 4.0, 3.74, 4.0, 3.0, 3.61, 3.74, 3.61, ...</td>\n",
       "      <td>clear</td>\n",
       "      <td>[8, 8, 8, 7, 7, 7, 8, 7, 7, 7, 6, 6, 9, 8, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>bloody</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data jw_word                                           jw_score  \\\n",
       "0       clear   clear  [0.9957737255096435, 0.9983007303873699, 0.993...   \n",
       "1      cloudy  cloudy  [0.965404487074467, 0.9533089855261015, 0.9696...   \n",
       "2        hazy    hazy  [0.969675800925807, 0.9784476189864308, 0.9663...   \n",
       "3       straw   straw  [1.0, 0.9938768100738525, 0.997392733891805, 0...   \n",
       "4      yellow  yellow  [0.9619675786871659, 0.9662853140580027, 0.969...   \n",
       "5       amber   amber  [0.9938768100738525, 1.0, 0.9957975864410401, ...   \n",
       "6       brown   brown  [0.997392733891805, 0.9957975864410401, 1.0, 0...   \n",
       "7     reddish     red  [0.9735094492059004, 0.9610682778609426, 0.965...   \n",
       "8      orange  orange  [0.9661128830491451, 0.9556621183428847, 0.975...   \n",
       "9         red     red  [0.9358082516988118, 0.9571988254123264, 0.928...   \n",
       "10      other   other  [0.995766019821167, 0.997296126683553, 0.99521...   \n",
       "11      green   green  [0.9399764442443849, 0.9599735514322917, 0.933...   \n",
       "12  colorless  yellow  [0.8949912276922488, 0.89462890625, 0.89499137...   \n",
       "\n",
       "   euc_word                                          euc_score lev_word  \\\n",
       "0     clear  [2.45, 2.0, 2.83, 2.45, 2.65, 2.24, 2.0, 2.24,...    clear   \n",
       "1    cloudy  [3.32, 3.32, 3.0, 3.61, 2.45, 3.16, 2.65, 2.45...   cloudy   \n",
       "2      hazy  [2.65, 2.65, 3.0, 3.32, 3.16, 2.83, 2.65, 2.83...     hazy   \n",
       "3     straw  [0.0, 2.45, 2.45, 3.16, 3.32, 2.65, 2.83, 3.0,...    straw   \n",
       "4    yellow  [3.32, 3.32, 3.0, 3.32, 0.0, 3.16, 3.0, 2.45, ...   yellow   \n",
       "5     amber  [2.45, 0.0, 2.45, 2.45, 3.32, 2.24, 2.45, 2.24...    amber   \n",
       "6     brown  [2.45, 2.45, 0.0, 2.83, 3.0, 2.24, 2.83, 2.65,...    brown   \n",
       "7       red  [3.16, 3.16, 3.46, 3.16, 3.87, 3.32, 3.74, 3.3...      red   \n",
       "8    orange  [2.65, 2.24, 2.24, 1.73, 3.16, 0.0, 3.0, 2.83,...   orange   \n",
       "9       red  [2.45, 2.0, 2.45, 2.0, 3.0, 2.24, 2.83, 2.24, ...      red   \n",
       "10    other  [2.45, 2.45, 2.45, 2.45, 3.0, 2.24, 3.16, 2.65...    other   \n",
       "11    green  [3.16, 2.45, 2.83, 0.0, 3.32, 1.73, 3.46, 2.65...    green   \n",
       "12   yellow  [3.74, 4.0, 3.74, 4.0, 3.0, 3.61, 3.74, 3.61, ...    clear   \n",
       "\n",
       "                                        lev_score Measure   Final  \n",
       "0   [4, 4, 5, 4, 5, 6, 4, 4, 4, 4, 0, 4, 5, 6, 5]      jw   clear  \n",
       "1   [6, 6, 5, 6, 6, 6, 5, 4, 5, 6, 4, 0, 5, 6, 2]      jw  cloudy  \n",
       "2   [5, 5, 5, 5, 6, 5, 4, 4, 4, 5, 5, 5, 0, 6, 5]      jw    hazy  \n",
       "3   [0, 5, 4, 5, 5, 5, 5, 5, 4, 4, 4, 6, 5, 5, 6]      jw   straw  \n",
       "4   [5, 6, 5, 6, 0, 6, 5, 5, 5, 6, 5, 6, 6, 6, 5]      jw  yellow  \n",
       "5   [5, 0, 5, 4, 6, 5, 5, 4, 4, 3, 4, 6, 5, 5, 6]      jw   amber  \n",
       "6   [4, 5, 0, 3, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 4]      jw   brown  \n",
       "7   [7, 7, 7, 6, 6, 7, 7, 7, 4, 7, 7, 7, 7, 6, 7]      jw   straw  \n",
       "8   [5, 5, 5, 5, 6, 0, 5, 5, 5, 5, 6, 6, 5, 6, 6]      jw  orange  \n",
       "9   [4, 4, 4, 3, 5, 5, 5, 4, 0, 4, 4, 5, 4, 4, 5]      jw     red  \n",
       "10  [4, 3, 5, 4, 6, 5, 5, 4, 4, 0, 4, 6, 5, 6, 6]      jw   other  \n",
       "11  [5, 4, 3, 0, 6, 5, 5, 4, 3, 4, 4, 6, 5, 5, 6]      jw   green  \n",
       "12  [8, 8, 8, 7, 7, 7, 8, 7, 7, 7, 6, 6, 9, 8, 7]      jw  bloody  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Result table\n",
    "groups_agents[0].report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>jw_word</th>\n",
       "      <th>jw_score</th>\n",
       "      <th>euc_word</th>\n",
       "      <th>euc_score</th>\n",
       "      <th>lev_word</th>\n",
       "      <th>lev_score</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg -</td>\n",
       "      <td>neg</td>\n",
       "      <td>[0.9463169642857142, 0.9880056381225586, 0.843...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[1.41, 2.83, 2.45, 3.0, 3.74, 4.58]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[2, 5, 5, 5, 5, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+</td>\n",
       "      <td>+</td>\n",
       "      <td>[0.9221540178571429, 0.8298543294270834, 1.0, ...</td>\n",
       "      <td>+</td>\n",
       "      <td>[2.0, 2.45, 0.0, 1.0, 2.0, 3.0]</td>\n",
       "      <td>+</td>\n",
       "      <td>[3, 5, 0, 1, 2, 3]</td>\n",
       "      <td>jw</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>++</td>\n",
       "      <td>+</td>\n",
       "      <td>[0.8875, 0.7916666666666666, 0.975, 1.0, 0.975...</td>\n",
       "      <td>++</td>\n",
       "      <td>[2.65, 3.0, 1.0, 0.0, 1.0, 2.0]</td>\n",
       "      <td>++</td>\n",
       "      <td>[3, 5, 1, 0, 1, 2]</td>\n",
       "      <td>jw</td>\n",
       "      <td>++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+++</td>\n",
       "      <td>+</td>\n",
       "      <td>[0.8875, 0.7916666666666666, 0.975, 0.975, 1.0...</td>\n",
       "      <td>+++</td>\n",
       "      <td>[3.46, 3.74, 2.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>+++</td>\n",
       "      <td>[3, 5, 2, 1, 0, 1]</td>\n",
       "      <td>jw</td>\n",
       "      <td>+++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 tr</td>\n",
       "      <td>trace</td>\n",
       "      <td>[0.9508489990234374, 0.9513668484157987, 0.917...</td>\n",
       "      <td>trace</td>\n",
       "      <td>[2.65, 2.24, 2.24, 2.83, 3.61, 4.47]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[4, 5, 4, 4, 4, 4]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25 tr</td>\n",
       "      <td>trace</td>\n",
       "      <td>[0.9138508387974331, 0.993138313293457, 0.8916...</td>\n",
       "      <td>trace</td>\n",
       "      <td>[2.83, 2.45, 2.45, 3.0, 3.74, 4.58]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>norm -</td>\n",
       "      <td>neg</td>\n",
       "      <td>[0.8810962383563703, 0.9556935628255209, 0.848...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[2.65, 3.0, 2.65, 3.16, 3.87, 4.69]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[5, 5, 6, 6, 6, 6]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50 tr</td>\n",
       "      <td>trace</td>\n",
       "      <td>[0.9138547624860491, 0.9931421279907227, 0.855...</td>\n",
       "      <td>trace</td>\n",
       "      <td>[2.83, 2.45, 2.45, 3.0, 3.74, 4.58]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>++++</td>\n",
       "      <td>+</td>\n",
       "      <td>[0.8875, 0.7916666666666666, 0.975, 0.975, 0.9...</td>\n",
       "      <td>++++</td>\n",
       "      <td>[4.36, 4.58, 3.0, 2.0, 1.0, 0.0]</td>\n",
       "      <td>++++</td>\n",
       "      <td>[4, 5, 3, 2, 1, 0]</td>\n",
       "      <td>jw</td>\n",
       "      <td>++++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10 tr</td>\n",
       "      <td>trace</td>\n",
       "      <td>[0.9135199410574777, 0.9983097712198893, 0.855...</td>\n",
       "      <td>trace</td>\n",
       "      <td>[2.83, 2.45, 2.45, 3.0, 3.74, 4.58]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1 tr</td>\n",
       "      <td>trace</td>\n",
       "      <td>[0.9520599365234376, 0.9568790011935763, 0.917...</td>\n",
       "      <td>trace</td>\n",
       "      <td>[2.65, 2.24, 2.24, 2.83, 3.61, 4.47]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[4, 5, 4, 4, 4, 4]</td>\n",
       "      <td>jw</td>\n",
       "      <td>trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>norm</td>\n",
       "      <td>neg</td>\n",
       "      <td>[0.9564813232421876, 0.946492173936632, 0.9079...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[2.24, 2.65, 2.24, 2.83, 3.61, 4.47]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[3, 5, 4, 4, 4, 4]</td>\n",
       "      <td>jw</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>[1.0, 0.9043306623186383, 0.9193080357142857, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[0.0, 2.45, 2.0, 2.65, 3.46, 4.36]</td>\n",
       "      <td>neg</td>\n",
       "      <td>[0, 5, 3, 3, 3, 4]</td>\n",
       "      <td>jw</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Data jw_word                                           jw_score  \\\n",
       "0    neg -     neg  [0.9463169642857142, 0.9880056381225586, 0.843...   \n",
       "1        +       +  [0.9221540178571429, 0.8298543294270834, 1.0, ...   \n",
       "2       ++       +  [0.8875, 0.7916666666666666, 0.975, 1.0, 0.975...   \n",
       "3      +++       +  [0.8875, 0.7916666666666666, 0.975, 0.975, 1.0...   \n",
       "4     5 tr   trace  [0.9508489990234374, 0.9513668484157987, 0.917...   \n",
       "5    25 tr   trace  [0.9138508387974331, 0.993138313293457, 0.8916...   \n",
       "6   norm -     neg  [0.8810962383563703, 0.9556935628255209, 0.848...   \n",
       "7    50 tr   trace  [0.9138547624860491, 0.9931421279907227, 0.855...   \n",
       "8     ++++       +  [0.8875, 0.7916666666666666, 0.975, 0.975, 0.9...   \n",
       "9    10 tr   trace  [0.9135199410574777, 0.9983097712198893, 0.855...   \n",
       "10    1 tr   trace  [0.9520599365234376, 0.9568790011935763, 0.917...   \n",
       "11    norm     neg  [0.9564813232421876, 0.946492173936632, 0.9079...   \n",
       "12     neg     neg  [1.0, 0.9043306623186383, 0.9193080357142857, ...   \n",
       "\n",
       "   euc_word                             euc_score lev_word  \\\n",
       "0       neg   [1.41, 2.83, 2.45, 3.0, 3.74, 4.58]      neg   \n",
       "1         +       [2.0, 2.45, 0.0, 1.0, 2.0, 3.0]        +   \n",
       "2        ++       [2.65, 3.0, 1.0, 0.0, 1.0, 2.0]       ++   \n",
       "3       +++      [3.46, 3.74, 2.0, 1.0, 0.0, 1.0]      +++   \n",
       "4     trace  [2.65, 2.24, 2.24, 2.83, 3.61, 4.47]      neg   \n",
       "5     trace   [2.83, 2.45, 2.45, 3.0, 3.74, 4.58]      neg   \n",
       "6       neg   [2.65, 3.0, 2.65, 3.16, 3.87, 4.69]      neg   \n",
       "7     trace   [2.83, 2.45, 2.45, 3.0, 3.74, 4.58]      neg   \n",
       "8      ++++      [4.36, 4.58, 3.0, 2.0, 1.0, 0.0]     ++++   \n",
       "9     trace   [2.83, 2.45, 2.45, 3.0, 3.74, 4.58]      neg   \n",
       "10    trace  [2.65, 2.24, 2.24, 2.83, 3.61, 4.47]      neg   \n",
       "11      neg  [2.24, 2.65, 2.24, 2.83, 3.61, 4.47]      neg   \n",
       "12      neg    [0.0, 2.45, 2.0, 2.65, 3.46, 4.36]      neg   \n",
       "\n",
       "             lev_score Measure  Final  \n",
       "0   [2, 5, 5, 5, 5, 5]      jw  trace  \n",
       "1   [3, 5, 0, 1, 2, 3]      jw      +  \n",
       "2   [3, 5, 1, 0, 1, 2]      jw     ++  \n",
       "3   [3, 5, 2, 1, 0, 1]      jw    +++  \n",
       "4   [4, 5, 4, 4, 4, 4]      jw  trace  \n",
       "5   [5, 5, 5, 5, 5, 5]      jw  trace  \n",
       "6   [5, 5, 6, 6, 6, 6]      jw  trace  \n",
       "7   [5, 5, 5, 5, 5, 5]      jw  trace  \n",
       "8   [4, 5, 3, 2, 1, 0]      jw   ++++  \n",
       "9   [5, 5, 5, 5, 5, 5]      jw  trace  \n",
       "10  [4, 5, 4, 4, 4, 4]      jw  trace  \n",
       "11  [3, 5, 4, 4, 4, 4]      jw    neg  \n",
       "12  [0, 5, 3, 3, 3, 4]      jw    neg  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_agents[1].report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups_agents[2].report_df.to_csv(\"negpos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>jw_word</th>\n",
       "      <th>jw_score</th>\n",
       "      <th>euc_word</th>\n",
       "      <th>euc_score</th>\n",
       "      <th>lev_word</th>\n",
       "      <th>lev_score</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>[1.0, 0.9826086956521739, 0.9999986731487772, ...</td>\n",
       "      <td>a</td>\n",
       "      <td>[0.0, 1.41, 1.41, 1.0, 2.0, 2.0, 2.0, 2.65, 2....</td>\n",
       "      <td>a</td>\n",
       "      <td>[0, 1, 1, 1, 4, 3, 3, 7, 4, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o</td>\n",
       "      <td>a</td>\n",
       "      <td>[0.9999995559885883, 0.9710144927536232, 0.999...</td>\n",
       "      <td>a</td>\n",
       "      <td>[1.41, 1.41, 1.41, 1.73, 2.45, 2.0, 2.0, 3.32,...</td>\n",
       "      <td>a</td>\n",
       "      <td>[1, 1, 1, 2, 5, 3, 3, 8, 5, 8]</td>\n",
       "      <td>jw</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>[0.9826086956521739, 1.0, 0.9994554602581521, ...</td>\n",
       "      <td>b</td>\n",
       "      <td>[1.41, 0.0, 1.41, 1.0, 2.0, 2.0, 2.0, 3.32, 2....</td>\n",
       "      <td>b</td>\n",
       "      <td>[1, 0, 1, 1, 4, 3, 3, 8, 5, 8]</td>\n",
       "      <td>jw</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab</td>\n",
       "      <td>ab</td>\n",
       "      <td>[0.9826086956521739, 0.9809041501976286, 0.982...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[1.0, 1.0, 1.73, 0.0, 1.73, 2.24, 2.24, 2.83, ...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[1, 1, 2, 0, 3, 3, 3, 7, 4, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bmt</td>\n",
       "      <td>b</td>\n",
       "      <td>[0.9651984994702705, 0.9628178377329192, 0.965...</td>\n",
       "      <td>b</td>\n",
       "      <td>[2.0, 1.41, 2.0, 1.73, 2.45, 2.45, 2.45, 3.32,...</td>\n",
       "      <td>b</td>\n",
       "      <td>[3, 2, 3, 3, 5, 3, 3, 7, 5, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>rh+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a2b</td>\n",
       "      <td>ab</td>\n",
       "      <td>[0.9652173913043479, 0.9627620341614906, 0.965...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[1.41, 1.41, 2.0, 1.0, 2.0, 2.45, 2.45, 3.0, 2...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[2, 2, 3, 1, 4, 3, 3, 7, 4, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>rh+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a2b3</td>\n",
       "      <td>ab</td>\n",
       "      <td>[0.9478254384579866, 0.9427479619565217, 0.947...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[1.73, 1.73, 2.24, 1.41, 2.24, 2.65, 2.65, 3.1...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[3, 3, 4, 2, 5, 4, 4, 7, 5, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>rh+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a1b3</td>\n",
       "      <td>ab</td>\n",
       "      <td>[0.9478254384579866, 0.9428236455502718, 0.947...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[1.73, 1.73, 2.24, 1.41, 2.24, 2.65, 2.65, 3.1...</td>\n",
       "      <td>ab</td>\n",
       "      <td>[3, 3, 4, 2, 5, 4, 4, 7, 5, 7]</td>\n",
       "      <td>jw</td>\n",
       "      <td>rh+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a3</td>\n",
       "      <td>a</td>\n",
       "      <td>[0.982608106108051, 0.9652173913043479, 0.9826...</td>\n",
       "      <td>a</td>\n",
       "      <td>[1.0, 1.73, 1.73, 1.41, 2.24, 2.24, 2.24, 2.83...</td>\n",
       "      <td>a</td>\n",
       "      <td>[1, 2, 2, 1, 4, 3, 3, 7, 4, 7]</td>\n",
       "      <td>Eucl</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b3</td>\n",
       "      <td>b</td>\n",
       "      <td>[0.9826083835405794, 0.9809041501976286, 0.982...</td>\n",
       "      <td>b</td>\n",
       "      <td>[1.73, 1.0, 1.73, 1.41, 2.24, 2.24, 2.24, 3.46...</td>\n",
       "      <td>b</td>\n",
       "      <td>[2, 1, 2, 2, 5, 3, 3, 8, 5, 8]</td>\n",
       "      <td>jw</td>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data jw_word                                           jw_score euc_word  \\\n",
       "0     a       a  [1.0, 0.9826086956521739, 0.9999986731487772, ...        a   \n",
       "1     o       a  [0.9999995559885883, 0.9710144927536232, 0.999...        a   \n",
       "2     b       b  [0.9826086956521739, 1.0, 0.9994554602581521, ...        b   \n",
       "3    ab      ab  [0.9826086956521739, 0.9809041501976286, 0.982...       ab   \n",
       "4   bmt       b  [0.9651984994702705, 0.9628178377329192, 0.965...        b   \n",
       "5   a2b      ab  [0.9652173913043479, 0.9627620341614906, 0.965...       ab   \n",
       "6  a2b3      ab  [0.9478254384579866, 0.9427479619565217, 0.947...       ab   \n",
       "7  a1b3      ab  [0.9478254384579866, 0.9428236455502718, 0.947...       ab   \n",
       "8    a3       a  [0.982608106108051, 0.9652173913043479, 0.9826...        a   \n",
       "9    b3       b  [0.9826083835405794, 0.9809041501976286, 0.982...        b   \n",
       "\n",
       "                                           euc_score lev_word  \\\n",
       "0  [0.0, 1.41, 1.41, 1.0, 2.0, 2.0, 2.0, 2.65, 2....        a   \n",
       "1  [1.41, 1.41, 1.41, 1.73, 2.45, 2.0, 2.0, 3.32,...        a   \n",
       "2  [1.41, 0.0, 1.41, 1.0, 2.0, 2.0, 2.0, 3.32, 2....        b   \n",
       "3  [1.0, 1.0, 1.73, 0.0, 1.73, 2.24, 2.24, 2.83, ...       ab   \n",
       "4  [2.0, 1.41, 2.0, 1.73, 2.45, 2.45, 2.45, 3.32,...        b   \n",
       "5  [1.41, 1.41, 2.0, 1.0, 2.0, 2.45, 2.45, 3.0, 2...       ab   \n",
       "6  [1.73, 1.73, 2.24, 1.41, 2.24, 2.65, 2.65, 3.1...       ab   \n",
       "7  [1.73, 1.73, 2.24, 1.41, 2.24, 2.65, 2.65, 3.1...       ab   \n",
       "8  [1.0, 1.73, 1.73, 1.41, 2.24, 2.24, 2.24, 2.83...        a   \n",
       "9  [1.73, 1.0, 1.73, 1.41, 2.24, 2.24, 2.24, 3.46...        b   \n",
       "\n",
       "                        lev_score Measure Final  \n",
       "0  [0, 1, 1, 1, 4, 3, 3, 7, 4, 7]      jw     a  \n",
       "1  [1, 1, 1, 2, 5, 3, 3, 8, 5, 8]      jw     a  \n",
       "2  [1, 0, 1, 1, 4, 3, 3, 8, 5, 8]      jw     b  \n",
       "3  [1, 1, 2, 0, 3, 3, 3, 7, 4, 7]      jw    ab  \n",
       "4  [3, 2, 3, 3, 5, 3, 3, 7, 5, 7]      jw   rh+  \n",
       "5  [2, 2, 3, 1, 4, 3, 3, 7, 4, 7]      jw   rh+  \n",
       "6  [3, 3, 4, 2, 5, 4, 4, 7, 5, 7]      jw   rh+  \n",
       "7  [3, 3, 4, 2, 5, 4, 4, 7, 5, 7]      jw   rh+  \n",
       "8  [1, 2, 2, 1, 4, 3, 3, 7, 4, 7]    Eucl     a  \n",
       "9  [2, 1, 2, 2, 5, 3, 3, 8, 5, 8]      jw    ab  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_agents[3].report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups_agents[4].report_df.to_csv(\"reac.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
